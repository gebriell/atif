End logger: end model inference
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7D442B289940), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x75DE66945840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 137/490 = 28.0%
F1 score 0.2767
TPR score 0.1606, FPR 0.0000
TP 22.0000, FP 0.0000
FN 115.0000, TN 490.0000
auc nan
accuracy 0.8166
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7B5F5A7D5940), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 137/490 = 28.0%
F1 score 0.2767
TPR score 0.1606, FPR 0.0000
TP 22.0000, FP 0.0000
FN 115.0000, TN 490.0000
auc nan
accuracy 0.8166
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x74382D1B5940), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 137/490 = 28.0%
F1 score 0.7706
TPR score 0.9562, FPR 0.1469
TP 131.0000, FP 72.0000
FN 6.0000, TN 418.0000
auc nan
accuracy 0.8756
End logger: end model inference
End logger: end model inference
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x78EABFF39840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2547
TPR score 0.7853, FPR 0.4183
TP 150.0000, FP 837.0000
FN 41.0000, TN 1164.0000
auc nan
accuracy 0.5995
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x72064A889840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3184
TPR score 0.2042, FPR 0.0075
TP 39.0000, FP 15.0000
FN 152.0000, TN 1986.0000
auc nan
accuracy 0.9238
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x799842A55840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2547
TPR score 0.7853, FPR 0.4183
TP 150.0000, FP 837.0000
FN 41.0000, TN 1164.0000
auc nan
accuracy 0.5995
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x730E64929840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3184
TPR score 0.2042, FPR 0.0075
TP 39.0000, FP 15.0000
FN 152.0000, TN 1986.0000
auc nan
accuracy 0.9238
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7091F34D9840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2547
TPR score 0.7853, FPR 0.4183
TP 150.0000, FP 837.0000
FN 41.0000, TN 1164.0000
auc nan
accuracy 0.5995
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7328DF2DD840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
///////////////////////////////////////////////////////
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=20,
                random_state=RandomState(MT19937) at 0x7DB07B19D740), '_original_if_offset': -0.6, '_n_estimators': 20, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3594
TPR score 0.2408, FPR 0.0095
TP 46.0000, FP 19.0000
FN 145.0000, TN 1982.0000
auc nan
accuracy 0.9252
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=20,
                random_state=RandomState(MT19937) at 0x752F288D5840), '_original_if_offset': None, '_n_estimators': 20, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3102
TPR score 0.8639, FPR 0.3538
TP 165.0000, FP 708.0000
FN 26.0000, TN 1293.0000
auc nan
accuracy 0.6651
End logger: end model inference
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=25,
                random_state=RandomState(MT19937) at 0x701D4E8D5840), '_original_if_offset': None, '_n_estimators': 25, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3102
TPR score 0.8639, FPR 0.3538
TP 165.0000, FP 708.0000
FN 26.0000, TN 1293.0000
auc nan
accuracy 0.6651
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=50,
                random_state=RandomState(MT19937) at 0x75FA5E129840), '_original_if_offset': None, '_n_estimators': 50, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3102
TPR score 0.8639, FPR 0.3538
TP 165.0000, FP 708.0000
FN 26.0000, TN 1293.0000
auc nan
accuracy 0.6651
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=75,
                random_state=RandomState(MT19937) at 0x7785FE6B1840), '_original_if_offset': None, '_n_estimators': 75, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3102
TPR score 0.8639, FPR 0.3538
TP 165.0000, FP 708.0000
FN 26.0000, TN 1293.0000
auc nan
accuracy 0.6651
End logger: end model inference
------------------------------------------------------------------
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x75AFF6039840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=200,
                random_state=RandomState(MT19937) at 0x79BC6CC89840), '_original_if_offset': None, '_n_estimators': 200, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3554
TPR score 0.6754, FPR 0.2029
TP 129.0000, FP 406.0000
FN 62.0000, TN 1595.0000
auc nan
accuracy 0.7865
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=200,
                random_state=RandomState(MT19937) at 0x711897855840), '_original_if_offset': None, '_n_estimators': 200, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3554
TPR score 0.6754, FPR 0.2029
TP 129.0000, FP 406.0000
FN 62.0000, TN 1595.0000
auc nan
accuracy 0.7865
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7E1042A11540), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 137/490 = 28.0%
F1 score 0.8037
TPR score 0.9562, FPR 0.1184
TP 131.0000, FP 58.0000
FN 6.0000, TN 432.0000
auc nan
accuracy 0.8979
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7AED46191840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x71D480545840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7750C1399840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x76A015AB5840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7D559B48D840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2954
TPR score 0.1832, FPR 0.0055
TP 35.0000, FP 11.0000
FN 156.0000, TN 1990.0000
auc nan
accuracy 0.9238
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x789F52E89840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3622
TPR score 0.2408, FPR 0.0085
TP 46.0000, FP 17.0000
FN 145.0000, TN 1984.0000
auc nan
accuracy 0.9261
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x739348C39840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7FA52B405840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.1, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x77F3C0D49840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.1, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=200,
                random_state=RandomState(MT19937) at 0x78A58B0D5840), '_original_if_offset': None, '_n_estimators': 200, '_eps': 1.0, '_softmax_tau': 0.6, '_attention_sigma_threshold': 0.9, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.0000
TPR score 0.0000, FPR 0.0000
TP 0.0000, FP 0.0000
FN 191.0000, TN 2001.0000
auc nan
accuracy 0.9129
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=200,
                random_state=RandomState(MT19937) at 0x7BA25D6B5840), '_original_if_offset': None, '_n_estimators': 200, '_eps': 1.0, '_softmax_tau': 0.6, '_attention_sigma_threshold': 0.9, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.0000
TPR score 0.0000, FPR 0.0000
TP 0.0000, FP 0.0000
FN 191.0000, TN 2001.0000
auc nan
accuracy 0.9129
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=1000,
                random_state=RandomState(MT19937) at 0x79C484BB9840), '_original_if_offset': None, '_n_estimators': 1000, '_eps': 1.0, '_softmax_tau': 0.1, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2774
TPR score 0.6492, FPR 0.2894
TP 124.0000, FP 579.0000
FN 67.0000, TN 1422.0000
auc nan
accuracy 0.7053
End logger: end model inference
||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x73368DBA1840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 0.0, '_softmax_tau': 0.3, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7AF8314AD840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 0.0, '_softmax_tau': 0.4, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x794C084D1840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.7, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
Precision score 0.2509
Recall score 0.7539
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7C60D808D840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 5.5, '_softmax_tau': 0.7, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.2210
Precision score 0.1296
Recall score 0.7487
TPR score 0.7487, FPR 0.4798
TP 143.0000, FP 960.0000
FN 48.0000, TN 1041.0000
auc nan
accuracy 0.5401
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x70B6A20DD840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.6, '_attention_sigma_threshold': 0.9, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.0000
Precision score 0.0000
Recall score 0.0000
TPR score 0.0000, FPR 0.0000
TP 0.0000, FP 0.0000
FN 191.0000, TN 2001.0000
auc nan
accuracy 0.9129
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x70ECB0EB5840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.6, '_attention_sigma_threshold': 0.1, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7690925B5840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.5, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
Precision score 0.2509
Recall score 0.7539
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x77B9C73A1840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 1.0, '_softmax_tau': 0.3, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3765
Precision score 0.2509
Recall score 0.7539
TPR score 0.7539, FPR 0.2149
TP 144.0000, FP 430.0000
FN 47.0000, TN 1571.0000
auc nan
accuracy 0.7824
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x77860DAD5840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 0.75, '_softmax_tau': 0.75, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=250,
                random_state=RandomState(MT19937) at 0x7BBD2BC89840), '_original_if_offset': None, '_n_estimators': 250, '_eps': 0.75, '_softmax_tau': 0.75, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=250,
                random_state=RandomState(MT19937) at 0x70C1BAF4D840), '_original_if_offset': None, '_n_estimators': 250, '_eps': 0.75, '_softmax_tau': 0.2, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=250,
                random_state=RandomState(MT19937) at 0x74F837AD5840), '_original_if_offset': None, '_n_estimators': 250, '_eps': 0.25, '_softmax_tau': 0.7, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x780DB813D840), '_original_if_offset': None, '_n_estimators': 150, '_eps': 0.25, '_softmax_tau': 0.8, '_attention_sigma_threshold': 0.5, '_sigma': None, '_w': None, '_mode': <Mode.ATTENTION: 1>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
End logger: end model optimization
End logger: end model optimization
End logger: end model optimization
End logger: end model optimization
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7FC6C24D5840), '_original_if_offset': -0.6, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.3622
Precision score 0.7302
Recall score 0.2408
TPR score 0.2408, FPR 0.0085
TP 46.0000, FP 17.0000
FN 145.0000, TN 1984.0000
auc nan
accuracy 0.9261
End logger: end model inference
Start logger: model: <class 'atif.models.attention_based_isolation_forest_sklearn.AttentionBasedIsolationForestSklearn'>: {'_logger': None, '_clf': IsolationForest(n_estimators=150,
                random_state=RandomState(MT19937) at 0x7E3CBE52D840), '_original_if_offset': -0.3, '_n_estimators': 150, '_eps': None, '_softmax_tau': None, '_attention_sigma_threshold': None, '_sigma': None, '_w': None, '_mode': <Mode.CLASSIC: (0,)>}
Proportion anomalies/normal = 191/2001 = 9.5%
F1 score 0.1603
Precision score 0.0871
Recall score 1.0000
TPR score 1.0000, FPR 1.0000
TP 191.0000, FP 2001.0000
FN 0.0000, TN 0.0000
auc nan
accuracy 0.0871
End logger: end model inference
